{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da4ea63c-e4d8-4e48-ab69-d9e670f7ea7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\tiago filho\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.3)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.0-cp312-cp312-win_amd64.whl.metadata (15 kB)\n",
      "Requirement already satisfied: pyarrow in c:\\users\\tiago filho\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (18.0.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\tiago filho\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\tiago filho\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\tiago filho\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\tiago filho\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.2)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.15.0-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\tiago filho\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading scikit_learn-1.6.0-cp312-cp312-win_amd64.whl (11.1 MB)\n",
      "   ---------------------------------------- 0.0/11.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/11.1 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/11.1 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/11.1 MB 1.1 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 0.8/11.1 MB 1.0 MB/s eta 0:00:11\n",
      "   --- ------------------------------------ 1.0/11.1 MB 1.1 MB/s eta 0:00:10\n",
      "   --- ------------------------------------ 1.0/11.1 MB 1.1 MB/s eta 0:00:10\n",
      "   ---- ----------------------------------- 1.3/11.1 MB 1.0 MB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 1.6/11.1 MB 964.5 kB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 1.6/11.1 MB 964.5 kB/s eta 0:00:10\n",
      "   ------ --------------------------------- 1.8/11.1 MB 959.1 kB/s eta 0:00:10\n",
      "   ------- -------------------------------- 2.1/11.1 MB 955.2 kB/s eta 0:00:10\n",
      "   -------- ------------------------------- 2.4/11.1 MB 952.0 kB/s eta 0:00:10\n",
      "   --------- ------------------------------ 2.6/11.1 MB 956.0 kB/s eta 0:00:09\n",
      "   --------- ------------------------------ 2.6/11.1 MB 956.0 kB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 2.9/11.1 MB 958.8 kB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 3.1/11.1 MB 961.2 kB/s eta 0:00:09\n",
      "   ------------ --------------------------- 3.4/11.1 MB 982.1 kB/s eta 0:00:08\n",
      "   ------------- -------------------------- 3.7/11.1 MB 1.0 MB/s eta 0:00:08\n",
      "   --------------- ------------------------ 4.2/11.1 MB 1.1 MB/s eta 0:00:07\n",
      "   ----------------- ---------------------- 5.0/11.1 MB 1.2 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 5.5/11.1 MB 1.3 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 6.3/11.1 MB 1.4 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 6.8/11.1 MB 1.4 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 7.9/11.1 MB 1.6 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 8.7/11.1 MB 1.7 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 9.4/11.1 MB 1.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 10.2/11.1 MB 1.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 10.7/11.1 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.1/11.1 MB 1.9 MB/s eta 0:00:00\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading scipy-1.15.0-cp312-cp312-win_amd64.whl (43.6 MB)\n",
      "   ---------------------------------------- 0.0/43.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.5/43.6 MB 3.4 MB/s eta 0:00:13\n",
      "    --------------------------------------- 1.0/43.6 MB 2.8 MB/s eta 0:00:16\n",
      "   - -------------------------------------- 1.6/43.6 MB 2.9 MB/s eta 0:00:15\n",
      "   - -------------------------------------- 2.1/43.6 MB 2.9 MB/s eta 0:00:15\n",
      "   -- ------------------------------------- 2.9/43.6 MB 2.8 MB/s eta 0:00:15\n",
      "   --- ------------------------------------ 3.4/43.6 MB 2.8 MB/s eta 0:00:15\n",
      "   --- ------------------------------------ 3.9/43.6 MB 2.8 MB/s eta 0:00:15\n",
      "   ---- ----------------------------------- 4.5/43.6 MB 2.7 MB/s eta 0:00:15\n",
      "   ---- ----------------------------------- 4.7/43.6 MB 2.7 MB/s eta 0:00:15\n",
      "   ----- ---------------------------------- 5.5/43.6 MB 2.7 MB/s eta 0:00:15\n",
      "   ----- ---------------------------------- 6.0/43.6 MB 2.7 MB/s eta 0:00:14\n",
      "   ------ --------------------------------- 6.6/43.6 MB 2.7 MB/s eta 0:00:14\n",
      "   ------ --------------------------------- 7.1/43.6 MB 2.7 MB/s eta 0:00:14\n",
      "   ------ --------------------------------- 7.3/43.6 MB 2.6 MB/s eta 0:00:14\n",
      "   ------- -------------------------------- 7.9/43.6 MB 2.5 MB/s eta 0:00:15\n",
      "   ------- -------------------------------- 8.1/43.6 MB 2.4 MB/s eta 0:00:15\n",
      "   ------- -------------------------------- 8.7/43.6 MB 2.5 MB/s eta 0:00:15\n",
      "   -------- ------------------------------- 9.2/43.6 MB 2.5 MB/s eta 0:00:15\n",
      "   -------- ------------------------------- 9.7/43.6 MB 2.4 MB/s eta 0:00:14\n",
      "   --------- ------------------------------ 10.0/43.6 MB 2.4 MB/s eta 0:00:14\n",
      "   --------- ------------------------------ 10.2/43.6 MB 2.4 MB/s eta 0:00:15\n",
      "   --------- ------------------------------ 10.7/43.6 MB 2.3 MB/s eta 0:00:15\n",
      "   ---------- ----------------------------- 11.0/43.6 MB 2.3 MB/s eta 0:00:15\n",
      "   ---------- ----------------------------- 11.3/43.6 MB 2.3 MB/s eta 0:00:15\n",
      "   ---------- ----------------------------- 11.8/43.6 MB 2.3 MB/s eta 0:00:15\n",
      "   ----------- ---------------------------- 12.3/43.6 MB 2.3 MB/s eta 0:00:14\n",
      "   ----------- ---------------------------- 12.8/43.6 MB 2.3 MB/s eta 0:00:14\n",
      "   ------------ --------------------------- 13.4/43.6 MB 2.3 MB/s eta 0:00:14\n",
      "   ------------ --------------------------- 13.9/43.6 MB 2.3 MB/s eta 0:00:14\n",
      "   ------------- -------------------------- 14.4/43.6 MB 2.3 MB/s eta 0:00:13\n",
      "   ------------- -------------------------- 14.9/43.6 MB 2.3 MB/s eta 0:00:13\n",
      "   -------------- ------------------------- 15.5/43.6 MB 2.3 MB/s eta 0:00:13\n",
      "   -------------- ------------------------- 15.7/43.6 MB 2.3 MB/s eta 0:00:13\n",
      "   -------------- ------------------------- 16.3/43.6 MB 2.3 MB/s eta 0:00:13\n",
      "   --------------- ------------------------ 17.0/43.6 MB 2.3 MB/s eta 0:00:12\n",
      "   ---------------- ----------------------- 17.6/43.6 MB 2.3 MB/s eta 0:00:12\n",
      "   ---------------- ----------------------- 17.8/43.6 MB 2.3 MB/s eta 0:00:12\n",
      "   ---------------- ----------------------- 18.4/43.6 MB 2.3 MB/s eta 0:00:11\n",
      "   ----------------- ---------------------- 18.9/43.6 MB 2.3 MB/s eta 0:00:11\n",
      "   ----------------- ---------------------- 19.1/43.6 MB 2.3 MB/s eta 0:00:11\n",
      "   ------------------ --------------------- 19.7/43.6 MB 2.3 MB/s eta 0:00:11\n",
      "   ------------------ --------------------- 19.9/43.6 MB 2.3 MB/s eta 0:00:11\n",
      "   ------------------ --------------------- 20.2/43.6 MB 2.2 MB/s eta 0:00:11\n",
      "   ------------------ --------------------- 20.4/43.6 MB 2.2 MB/s eta 0:00:11\n",
      "   ------------------- -------------------- 21.0/43.6 MB 2.2 MB/s eta 0:00:11\n",
      "   ------------------- -------------------- 21.5/43.6 MB 2.2 MB/s eta 0:00:10\n",
      "   ------------------- -------------------- 21.8/43.6 MB 2.2 MB/s eta 0:00:10\n",
      "   -------------------- ------------------- 22.3/43.6 MB 2.2 MB/s eta 0:00:10\n",
      "   -------------------- ------------------- 22.5/43.6 MB 2.2 MB/s eta 0:00:10\n",
      "   -------------------- ------------------- 22.8/43.6 MB 2.2 MB/s eta 0:00:10\n",
      "   --------------------- ------------------ 23.1/43.6 MB 2.2 MB/s eta 0:00:10\n",
      "   --------------------- ------------------ 23.3/43.6 MB 2.1 MB/s eta 0:00:10\n",
      "   --------------------- ------------------ 23.9/43.6 MB 2.1 MB/s eta 0:00:10\n",
      "   ---------------------- ----------------- 24.1/43.6 MB 2.1 MB/s eta 0:00:10\n",
      "   ---------------------- ----------------- 24.6/43.6 MB 2.1 MB/s eta 0:00:09\n",
      "   ---------------------- ----------------- 24.9/43.6 MB 2.1 MB/s eta 0:00:09\n",
      "   ----------------------- ---------------- 25.2/43.6 MB 2.1 MB/s eta 0:00:09\n",
      "   ----------------------- ---------------- 25.7/43.6 MB 2.1 MB/s eta 0:00:09\n",
      "   ----------------------- ---------------- 26.0/43.6 MB 2.1 MB/s eta 0:00:09\n",
      "   ------------------------ --------------- 26.2/43.6 MB 2.1 MB/s eta 0:00:09\n",
      "   ------------------------ --------------- 26.7/43.6 MB 2.1 MB/s eta 0:00:09\n",
      "   ------------------------ --------------- 27.0/43.6 MB 2.1 MB/s eta 0:00:09\n",
      "   ------------------------ --------------- 27.3/43.6 MB 2.0 MB/s eta 0:00:08\n",
      "   ------------------------- -------------- 27.8/43.6 MB 2.0 MB/s eta 0:00:08\n",
      "   ------------------------- -------------- 28.3/43.6 MB 2.1 MB/s eta 0:00:08\n",
      "   -------------------------- ------------- 28.8/43.6 MB 2.1 MB/s eta 0:00:08\n",
      "   -------------------------- ------------- 29.4/43.6 MB 2.1 MB/s eta 0:00:07\n",
      "   --------------------------- ------------ 30.4/43.6 MB 2.1 MB/s eta 0:00:07\n",
      "   ---------------------------- ----------- 31.2/43.6 MB 2.1 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 31.7/43.6 MB 2.1 MB/s eta 0:00:06\n",
      "   ----------------------------- ---------- 32.5/43.6 MB 2.2 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 33.0/43.6 MB 2.2 MB/s eta 0:00:05\n",
      "   ------------------------------- -------- 33.8/43.6 MB 2.2 MB/s eta 0:00:05\n",
      "   ------------------------------- -------- 34.3/43.6 MB 2.2 MB/s eta 0:00:05\n",
      "   ------------------------------- -------- 34.9/43.6 MB 2.2 MB/s eta 0:00:04\n",
      "   -------------------------------- ------- 35.4/43.6 MB 2.2 MB/s eta 0:00:04\n",
      "   -------------------------------- ------- 35.9/43.6 MB 2.2 MB/s eta 0:00:04\n",
      "   --------------------------------- ------ 36.4/43.6 MB 2.2 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 37.2/43.6 MB 2.2 MB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 37.7/43.6 MB 2.2 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 38.3/43.6 MB 2.2 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 38.8/43.6 MB 2.2 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 39.6/43.6 MB 2.3 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 40.1/43.6 MB 2.3 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 40.9/43.6 MB 2.3 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 41.4/43.6 MB 2.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 41.9/43.6 MB 2.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  42.7/43.6 MB 2.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  43.3/43.6 MB 2.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 43.6/43.6 MB 2.3 MB/s eta 0:00:00\n",
      "Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.6.0 scipy-1.15.0 threadpoolctl-3.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame carregado com sucesso.\n",
      "       id            title  vote_average  vote_count    status release_date  \\\n",
      "0   27205        Inception         8.364       34495  Released   2010-07-15   \n",
      "1  157336     Interstellar         8.417       32571  Released   2014-11-05   \n",
      "2     155  The Dark Knight         8.512       30619  Released   2008-07-16   \n",
      "3   19995           Avatar         7.573       29815  Released   2009-12-15   \n",
      "4   24428     The Avengers         7.710       29166  Released   2012-04-25   \n",
      "\n",
      "      revenue  runtime  adult                     backdrop_path  ...  \\\n",
      "0   825532764      148  False  /8ZTVqvKDQ8emSGUEMjsS4yHAwrp.jpg  ...   \n",
      "1   701729206      169  False  /pbrkL804c8yAv3zBZR4QPEafpAR.jpg  ...   \n",
      "2  1004558444      152  False  /nMKdUUepR0i5zn0y1T4CsSB5chy.jpg  ...   \n",
      "3  2923706026      162  False  /vL5LR6WdxWPjLPFRLe133jXWsh5.jpg  ...   \n",
      "4  1518815515      143  False  /9BBTo63ANSmhC4e6r62OJFuK2GL.jpg  ...   \n",
      "\n",
      "                                            overview popularity  \\\n",
      "0  Cobb, a skilled thief who commits corporate es...     83.952   \n",
      "1  The adventures of a group of explorers who mak...    140.241   \n",
      "2  Batman raises the stakes in his war on crime. ...    130.643   \n",
      "3  In the 22nd century, a paraplegic Marine is di...     79.932   \n",
      "4  When an unexpected enemy emerges and threatens...     98.082   \n",
      "\n",
      "                        poster_path  \\\n",
      "0  /oYuLEt3zVCKq57qu2F8dT7NIa6f.jpg   \n",
      "1  /gEU2QniE6E77NI6lCU6MxlNBvIx.jpg   \n",
      "2  /qJ2tW6WMUDux911r6m7haRef0WH.jpg   \n",
      "3  /kyeqWdyUXW608qlYkRqosgbbJyK.jpg   \n",
      "4   /RYMX2wcKCBAr24UyPD7xwmjaTn.jpg   \n",
      "\n",
      "                                             tagline  \\\n",
      "0               Your mind is the scene of the crime.   \n",
      "1  Mankind was born on Earth. It was never meant ...   \n",
      "2                  Welcome to a world without rules.   \n",
      "3                        Enter the world of Pandora.   \n",
      "4                            Some assembly required.   \n",
      "\n",
      "                                        genres  \\\n",
      "0           Action, Science Fiction, Adventure   \n",
      "1            Adventure, Drama, Science Fiction   \n",
      "2               Drama, Action, Crime, Thriller   \n",
      "3  Action, Adventure, Fantasy, Science Fiction   \n",
      "4           Science Fiction, Action, Adventure   \n",
      "\n",
      "                                production_companies  \\\n",
      "0  Legendary Pictures, Syncopy, Warner Bros. Pict...   \n",
      "1  Legendary Pictures, Syncopy, Lynda Obst Produc...   \n",
      "2  DC Comics, Legendary Pictures, Syncopy, Isobel...   \n",
      "3  Dune Entertainment, Lightstorm Entertainment, ...   \n",
      "4                                     Marvel Studios   \n",
      "\n",
      "                       production_countries  \\\n",
      "0  United Kingdom, United States of America   \n",
      "1  United Kingdom, United States of America   \n",
      "2  United Kingdom, United States of America   \n",
      "3  United States of America, United Kingdom   \n",
      "4                  United States of America   \n",
      "\n",
      "                     spoken_languages  \\\n",
      "0  English, French, Japanese, Swahili   \n",
      "1                             English   \n",
      "2                   English, Mandarin   \n",
      "3                    English, Spanish   \n",
      "4             English, Hindi, Russian   \n",
      "\n",
      "                                            keywords lucratividade  \n",
      "0  rescue, mission, dream, airplane, paris, franc...    muito_alta  \n",
      "1  rescue, future, spacecraft, race against time,...    muito_alta  \n",
      "2  joker, sadism, chaos, secret identity, crime f...    muito_alta  \n",
      "3  future, society, culture clash, space travel, ...    super_alta  \n",
      "4  new york city, superhero, shield, based on com...    super_alta  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "Dados preparados com sucesso.\n",
      "Divisão dos dados realizada com sucesso.\n",
      "Erro ao treinar o modelo: could not convert string to float: 'Once Upon a Sunday'\n",
      "Erro ao fazer previsões: 'RandomForestClassifier' object has no attribute 'estimators_'\n",
      "Erro ao avaliar o modelo: name 'y_pred' is not defined\n",
      "Erro ao atualizar a coluna 'lucratividade': 'RandomForestClassifier' object has no attribute 'estimators_'\n",
      "DataFrame atualizado salvo com sucesso.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas scikit-learn pyarrow\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Carregar o DataFrame\n",
    "try:\n",
    "\tdf = pd.read_parquet('TMDB_movie_dataset_v11(com correçao).parquet')\n",
    "\tprint(\"DataFrame carregado com sucesso.\")\n",
    "except Exception as e:\n",
    "\tprint(f\"Erro ao carregar o DataFrame: {e}\")\n",
    "\n",
    "# Verificar as primeiras linhas do DataFrame\n",
    "print(df.head())\n",
    "\n",
    "# Preparar os dados\n",
    "# Supondo que 'features' são as colunas que você usará para treinar o modelo\n",
    "# e 'lucratividade' é a coluna alvo\n",
    "try:\n",
    "\tfeatures = df.drop(columns=['lucratividade'])\n",
    "\ttarget = df['lucratividade']\n",
    "\tprint(\"Dados preparados com sucesso.\")\n",
    "except KeyError as e:\n",
    "\tprint(f\"Erro ao preparar os dados: {e}\")\n",
    "\n",
    "# Dividir os dados em conjuntos de treinamento e teste\n",
    "try:\n",
    "\tX_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\tprint(\"Divisão dos dados realizada com sucesso.\")\n",
    "except Exception as e:\n",
    "\tprint(f\"Erro ao dividir os dados: {e}\")\n",
    "\n",
    "# Treinar o modelo de Random Forest\n",
    "try:\n",
    "\tclf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\tclf.fit(X_train, y_train)\n",
    "\tprint(\"Modelo treinado com sucesso.\")\n",
    "except Exception as e:\n",
    "\tprint(f\"Erro ao treinar o modelo: {e}\")\n",
    "\n",
    "# Fazer previsões\n",
    "try:\n",
    "\ty_pred = clf.predict(X_test)\n",
    "\tprint(\"Previsões realizadas com sucesso.\")\n",
    "except Exception as e:\n",
    "\tprint(f\"Erro ao fazer previsões: {e}\")\n",
    "\n",
    "# Avaliar o modelo\n",
    "try:\n",
    "\tprint(classification_report(y_test, y_pred))\n",
    "\tprint(\"Avaliação do modelo realizada com sucesso.\")\n",
    "except Exception as e:\n",
    "\tprint(f\"Erro ao avaliar o modelo: {e}\")\n",
    "\n",
    "# Atualizar a coluna 'lucratividade' no DataFrame original\n",
    "try:\n",
    "\tdf['lucratividade'] = clf.predict(features)\n",
    "\tprint(\"Coluna 'lucratividade' atualizada com sucesso.\")\n",
    "except Exception as e:\n",
    "\tprint(f\"Erro ao atualizar a coluna 'lucratividade': {e}\")\n",
    "\n",
    "# Salvar o DataFrame atualizado\n",
    "try:\n",
    "\tdf.to_parquet('TMDB_movie_dataset_v11_atualizado.parquet')\n",
    "\tprint(\"DataFrame atualizado salvo com sucesso.\")\n",
    "except Exception as e:\n",
    "\tprint(f\"Erro ao salvar o DataFrame atualizado: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b567db24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\tiago filho\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\tiago filho\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.6.0)\n",
      "Requirement already satisfied: pyarrow in c:\\users\\tiago filho\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (18.0.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\tiago filho\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\tiago filho\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\tiago filho\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\tiago filho\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\tiago filho\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.15.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\tiago filho\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\tiago filho\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\tiago filho\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "DataFrame carregado com sucesso.\n",
      "       id            title  vote_average  vote_count    status release_date  \\\n",
      "0   27205        Inception         8.364       34495  Released   2010-07-15   \n",
      "1  157336     Interstellar         8.417       32571  Released   2014-11-05   \n",
      "2     155  The Dark Knight         8.512       30619  Released   2008-07-16   \n",
      "3   19995           Avatar         7.573       29815  Released   2009-12-15   \n",
      "4   24428     The Avengers         7.710       29166  Released   2012-04-25   \n",
      "\n",
      "      revenue  runtime  adult                     backdrop_path  ...  \\\n",
      "0   825532764      148  False  /8ZTVqvKDQ8emSGUEMjsS4yHAwrp.jpg  ...   \n",
      "1   701729206      169  False  /pbrkL804c8yAv3zBZR4QPEafpAR.jpg  ...   \n",
      "2  1004558444      152  False  /nMKdUUepR0i5zn0y1T4CsSB5chy.jpg  ...   \n",
      "3  2923706026      162  False  /vL5LR6WdxWPjLPFRLe133jXWsh5.jpg  ...   \n",
      "4  1518815515      143  False  /9BBTo63ANSmhC4e6r62OJFuK2GL.jpg  ...   \n",
      "\n",
      "                                            overview popularity  \\\n",
      "0  Cobb, a skilled thief who commits corporate es...     83.952   \n",
      "1  The adventures of a group of explorers who mak...    140.241   \n",
      "2  Batman raises the stakes in his war on crime. ...    130.643   \n",
      "3  In the 22nd century, a paraplegic Marine is di...     79.932   \n",
      "4  When an unexpected enemy emerges and threatens...     98.082   \n",
      "\n",
      "                        poster_path  \\\n",
      "0  /oYuLEt3zVCKq57qu2F8dT7NIa6f.jpg   \n",
      "1  /gEU2QniE6E77NI6lCU6MxlNBvIx.jpg   \n",
      "2  /qJ2tW6WMUDux911r6m7haRef0WH.jpg   \n",
      "3  /kyeqWdyUXW608qlYkRqosgbbJyK.jpg   \n",
      "4   /RYMX2wcKCBAr24UyPD7xwmjaTn.jpg   \n",
      "\n",
      "                                             tagline  \\\n",
      "0               Your mind is the scene of the crime.   \n",
      "1  Mankind was born on Earth. It was never meant ...   \n",
      "2                  Welcome to a world without rules.   \n",
      "3                        Enter the world of Pandora.   \n",
      "4                            Some assembly required.   \n",
      "\n",
      "                                        genres  \\\n",
      "0           Action, Science Fiction, Adventure   \n",
      "1            Adventure, Drama, Science Fiction   \n",
      "2               Drama, Action, Crime, Thriller   \n",
      "3  Action, Adventure, Fantasy, Science Fiction   \n",
      "4           Science Fiction, Action, Adventure   \n",
      "\n",
      "                                production_companies  \\\n",
      "0  Legendary Pictures, Syncopy, Warner Bros. Pict...   \n",
      "1  Legendary Pictures, Syncopy, Lynda Obst Produc...   \n",
      "2  DC Comics, Legendary Pictures, Syncopy, Isobel...   \n",
      "3  Dune Entertainment, Lightstorm Entertainment, ...   \n",
      "4                                     Marvel Studios   \n",
      "\n",
      "                       production_countries  \\\n",
      "0  United Kingdom, United States of America   \n",
      "1  United Kingdom, United States of America   \n",
      "2  United Kingdom, United States of America   \n",
      "3  United States of America, United Kingdom   \n",
      "4                  United States of America   \n",
      "\n",
      "                     spoken_languages  \\\n",
      "0  English, French, Japanese, Swahili   \n",
      "1                             English   \n",
      "2                   English, Mandarin   \n",
      "3                    English, Spanish   \n",
      "4             English, Hindi, Russian   \n",
      "\n",
      "                                            keywords lucratividade  \n",
      "0  rescue, mission, dream, airplane, paris, franc...    muito_alta  \n",
      "1  rescue, future, spacecraft, race against time,...    muito_alta  \n",
      "2  joker, sadism, chaos, secret identity, crime f...    muito_alta  \n",
      "3  future, society, culture clash, space travel, ...    super_alta  \n",
      "4  new york city, superhero, shield, based on com...    super_alta  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "                            precision    recall  f1-score   support\n",
      "\n",
      "                      alta       0.54      0.09      0.15       150\n",
      "                     baixo       0.33      0.02      0.04       171\n",
      "lucratividade_indisponivel       1.00      1.00      1.00    223624\n",
      "                     media       0.36      0.19      0.25       236\n",
      "                muito_alta       0.52      0.54      0.53       422\n",
      "               muito_baixo       0.67      0.02      0.04       105\n",
      "                  prejuizo       0.67      0.97      0.80      1220\n",
      "                super_alta       0.77      0.67      0.72       450\n",
      "\n",
      "                  accuracy                           1.00    226378\n",
      "                 macro avg       0.61      0.44      0.44    226378\n",
      "              weighted avg       1.00      1.00      0.99    226378\n",
      "\n",
      "DataFrame atualizado salvo com sucesso.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas scikit-learn pyarrow\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Carregar o DataFrame\n",
    "try:\n",
    "    df = pd.read_parquet('TMDB_movie_dataset_v11(com correçao).parquet')\n",
    "    print(\"DataFrame carregado com sucesso.\")\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao carregar o DataFrame: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Verificar as primeiras linhas do DataFrame\n",
    "print(df.head())\n",
    "\n",
    "# Verificar se 'lucratividade' existe no DataFrame\n",
    "if 'lucratividade' not in df.columns:\n",
    "    print(\"Erro: Coluna 'lucratividade' não encontrada no DataFrame.\")\n",
    "    exit()\n",
    "\n",
    "# Separar os recursos (features) e o alvo (target)\n",
    "features = df.drop(columns=['lucratividade'])\n",
    "target = df['lucratividade']\n",
    "\n",
    "# Verificar e converter colunas categóricas\n",
    "for col in features.select_dtypes(include=['object']).columns:\n",
    "    le = LabelEncoder()\n",
    "    features[col] = le.fit_transform(features[col])\n",
    "\n",
    "# Dividir os dados em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Treinar o modelo de Random Forest\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Fazer previsões\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Avaliar o modelo\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Fazer previsões apenas nos dados de teste\n",
    "df.loc[X_test.index, 'lucratividade_predita'] = y_pred\n",
    "\n",
    "# Salvar o DataFrame atualizado\n",
    "df.to_parquet('TMDB_movie_dataset_v11_atualizado.parquet')\n",
    "print(\"DataFrame atualizado salvo com sucesso.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e262ead8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Comparar as colunas 'lucratividade' e 'lucratividade_predita'\n",
    "comparison_df = df[['lucratividade', 'lucratividade_predita']].dropna()\n",
    "\n",
    "# Converter colunas para valores numéricos\n",
    "le = LabelEncoder()\n",
    "comparison_df['lucratividade'] = le.fit_transform(comparison_df['lucratividade'])\n",
    "comparison_df['lucratividade_predita'] = le.transform(comparison_df['lucratividade_predita'])\n",
    "\n",
    "# Plotar a comparação\n",
    "plt.figure(figsize=(10, 6))\n",
    "comparison_df.head(20).plot(kind='bar')\n",
    "plt.title('Comparação entre Lucratividade Real e Predita')\n",
    "plt.xlabel('Índice')\n",
    "plt.ylabel('Lucratividade')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(['Lucratividade Real', 'Lucratividade Predita'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d0b1c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tiago Filho\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:528: FitFailedWarning: \n",
      "111 fits failed out of a total of 300.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "58 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Tiago Filho\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Tiago Filho\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Tiago Filho\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Tiago Filho\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "53 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Tiago Filho\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Tiago Filho\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Tiago Filho\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Tiago Filho\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\Tiago Filho\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1107: UserWarning: One or more of the test scores are non-finite: [0.9954578  0.99519828        nan        nan 0.99499618 0.99419663\n",
      "        nan 0.99418006 0.99506575 0.99514306 0.9954832  0.99519717\n",
      "        nan        nan 0.99427393        nan 0.99549645 0.9954589\n",
      " 0.99503814        nan        nan 0.99514968        nan 0.99516735\n",
      " 0.99521484        nan        nan 0.99522809        nan 0.99519054\n",
      " 0.99542246 0.9952292         nan 0.99419111 0.99531865 0.99503483\n",
      " 0.99417233 0.99525791 0.99506686 0.99418006        nan 0.99544565\n",
      " 0.99532528 0.99498734        nan        nan 0.99526895 0.99522809\n",
      " 0.9950017  0.99426068 0.99526895        nan        nan 0.99419111\n",
      " 0.99519717        nan        nan        nan 0.99509557        nan\n",
      " 0.99503814 0.99427172        nan 0.99533963 0.99545007 0.99517729\n",
      "        nan 0.99529877        nan        nan 0.99521153 0.99524797\n",
      " 0.99498734        nan 0.9952292  0.99515631 0.99506575 0.99501716\n",
      "        nan 0.99528883        nan 0.9954335         nan        nan\n",
      " 0.99520932        nan        nan        nan        nan 0.99548099\n",
      " 0.99413368 0.99420767 0.9952292         nan 0.99420325 0.99527006\n",
      " 0.99528883 0.99524024        nan 0.99418227]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores hiperparâmetros encontrados:\n",
      "{'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': None, 'bootstrap': False}\n",
      "                            precision    recall  f1-score   support\n",
      "\n",
      "                      alta       0.50      0.07      0.13       150\n",
      "                     baixo       0.44      0.05      0.08       171\n",
      "lucratividade_indisponivel       1.00      1.00      1.00    223624\n",
      "                     media       0.35      0.22      0.27       236\n",
      "                muito_alta       0.55      0.53      0.54       422\n",
      "               muito_baixo       0.33      0.01      0.02       105\n",
      "                  prejuizo       0.69      0.98      0.81      1220\n",
      "                super_alta       0.75      0.70      0.73       450\n",
      "\n",
      "                  accuracy                           1.00    226378\n",
      "                 macro avg       0.58      0.44      0.45    226378\n",
      "              weighted avg       1.00      1.00      1.00    226378\n",
      "\n",
      "DataFrame atualizado salvo com sucesso.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Definir os hiperparâmetros a serem testados\n",
    "param_dist = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Configurar o RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(estimator=RandomForestClassifier(random_state=42), param_distributions=param_dist, \n",
    "                                   n_iter=100, cv=3, n_jobs=-1, verbose=2, scoring='accuracy', random_state=42)\n",
    "\n",
    "# Realizar a busca pelos melhores hiperparâmetros\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Exibir os melhores hiperparâmetros encontrados\n",
    "print(\"Melhores hiperparâmetros encontrados:\")\n",
    "print(random_search.best_params_)\n",
    "\n",
    "# Treinar o modelo com os melhores hiperparâmetros\n",
    "best_clf = random_search.best_estimator_\n",
    "best_clf.fit(X_train, y_train)\n",
    "\n",
    "# Fazer previsões\n",
    "y_pred = best_clf.predict(X_test)\n",
    "\n",
    "# Avaliar o modelo\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Fazer previsões apenas nos dados de teste\n",
    "df.loc[X_test.index, 'lucratividade_predita'] = y_pred\n",
    "\n",
    "# Salvar o DataFrame atualizado\n",
    "df.to_parquet('TMDB_movie_dataset_v11_atualizado.parquet')\n",
    "print(\"DataFrame atualizado salvo com sucesso.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "20d28d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            precision    recall  f1-score   support\n",
      "\n",
      "                      alta       0.50      0.07      0.13       150\n",
      "                     baixo       0.44      0.05      0.08       171\n",
      "lucratividade_indisponivel       1.00      1.00      1.00    223624\n",
      "                     media       0.35      0.22      0.27       236\n",
      "                muito_alta       0.55      0.53      0.54       422\n",
      "               muito_baixo       0.33      0.01      0.02       105\n",
      "                  prejuizo       0.69      0.98      0.81      1220\n",
      "                super_alta       0.75      0.70      0.73       450\n",
      "\n",
      "                  accuracy                           1.00    226378\n",
      "                 macro avg       0.58      0.44      0.45    226378\n",
      "              weighted avg       1.00      1.00      1.00    226378\n",
      "\n",
      "DataFrame atualizado salvo com sucesso.\n"
     ]
    }
   ],
   "source": [
    "# Treinar o modelo com os melhores hiperparâmetros\n",
    "best_clf = random_search.best_estimator_\n",
    "best_clf.fit(X_train, y_train)\n",
    "\n",
    "# Fazer previsões\n",
    "y_pred = best_clf.predict(X_test)\n",
    "\n",
    "# Avaliar o modelo\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Fazer previsões apenas nos dados de teste\n",
    "df.loc[X_test.index, 'lucratividade_predita'] = y_pred\n",
    "\n",
    "# Salvar o DataFrame atualizado\n",
    "df.to_parquet('TMDB_movie_dataset_v11_atualizado.parquet')\n",
    "print(\"DataFrame atualizado salvo com sucesso.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0401fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install seaborn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "# Carregar o DataFrame atualizado\n",
    "try:\n",
    "    df = pd.read_parquet('TMDB_movie_dataset_v11_atualizado.parquet')\n",
    "    print(\"DataFrame atualizado carregado com sucesso.\")\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao carregar o DataFrame atualizado: {e}\")\n",
    "\n",
    "# Comparar as colunas 'lucratividade' e 'lucratividade_predita'\n",
    "comparison_df = df[['lucratividade', 'lucratividade_predita']].dropna()\n",
    "\n",
    "# Converter colunas para valores numéricos\n",
    "le = LabelEncoder()\n",
    "comparison_df['lucratividade'] = le.fit_transform(comparison_df['lucratividade'])\n",
    "comparison_df['lucratividade_predita'] = le.transform(comparison_df['lucratividade_predita'])\n",
    "\n",
    "# Obter uma amostra representativa do DataFrame\n",
    "sample_df = comparison_df.sample(frac=0.01, random_state=42)  # 1% de amostra\n",
    "\n",
    "# Plotar a comparação\n",
    "plt.figure(figsize=(10, 6))\n",
    "sample_df.plot(kind='bar')\n",
    "plt.title('Comparação entre Lucratividade Real e Predita')\n",
    "plt.xlabel('Índice')\n",
    "plt.ylabel('Lucratividade')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(['Lucratividade Real', 'Lucratividade Predita'])\n",
    "\n",
    "# Converter colunas para valores numéricos usando MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "sample_df[['lucratividade', 'lucratividade_predita']] = scaler.fit_transform(sample_df[['lucratividade', 'lucratividade_predita']])\n",
    "\n",
    "# Plotar a comparação usando histograma\n",
    "plt.figure(figsize=(10, 6))\n",
    "sample_df.plot(kind='hist', alpha=0.5, bins=20)\n",
    "plt.title('Comparação entre Lucratividade Real e Predita')\n",
    "plt.xlabel('Lucratividade')\n",
    "plt.ylabel('Frequência')\n",
    "plt.legend(['Lucratividade Real', 'Lucratividade Predita'])\n",
    "plt.show()\n",
    "\n",
    "# Gerar a matriz de confusão\n",
    "y_test_encoded = le.transform(y_test)\n",
    "y_pred_encoded = le.transform(y_pred)\n",
    "cm = confusion_matrix(y_test_encoded, y_pred_encoded)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=le.classes_)\n",
    "\n",
    "# Plotar a matriz de confusão\n",
    "plt.figure(figsize=(10, 6))\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Matriz de Confusão')\n",
    "plt.show()\n",
    "# Gerar a matriz de confusão normalizada\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "disp_normalized = ConfusionMatrixDisplay(confusion_matrix=cm_normalized, display_labels=le.classes_)\n",
    "\n",
    "# Plotar a matriz de confusão normalizada\n",
    "plt.figure(figsize=(10, 6))\n",
    "disp_normalized.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Matriz de Confusão Normalizada')\n",
    "plt.show()\n",
    "\n",
    "# Plotar o boxplot\n",
    "plt.figure(figsize=(10, 6))\n",
    "comparison_df.boxplot()\n",
    "plt.title('Boxplot da Lucratividade Real e Predita')\n",
    "plt.xlabel('Tipo')\n",
    "plt.ylabel('Lucratividade')\n",
    "plt.xticks([1, 2], ['Lucratividade Real', 'Lucratividade Predita'])\n",
    "plt.show()\n",
    "\n",
    "# Plotar o gráfico de violino\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.violinplot(data=comparison_df)\n",
    "plt.title('Gráfico de Violino da Lucratividade Real e Predita')\n",
    "plt.xlabel('Tipo')\n",
    "plt.ylabel('Lucratividade')\n",
    "plt.xticks([0, 1], ['Lucratividade Real', 'Lucratividade Predita'])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
